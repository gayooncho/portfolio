df = read.csv(file = "data_comb.csv")
head(df)

# 이름변경
names(df) <- c("x", "district", "police", "cctv", "one_person", "pub", "crime")

#========================================================
# 상관관계 확인
#========================================================
# 불필요한 열 제거
#========================================================
df <- subset(df, select = -c(x, district))

#========================================================
# 상관관계 확인
#========================================================
cor(df, method = "pearson")

#========================================================
# 산점행렬도 그래프를 통한 데이터 분석
#========================================================
library(PerformanceAnalytics)
chart.Correlation(df, histogram =, pch="+")

#========================================================
### 회귀분석
#========================================================
# 통계 분석 (ANOVA) F-통계량 확인
#========================================================
df_lm <- lm(df$crime ~ df$police + df$cctv + df$one_person + df$pub, data = df)

anova(df_lm)
#========================================================
# P-value 값이 0.05보다 작음으로 모든 변수들은 회귀모델 구축에 유의미한 영향력을 가짐
#========================================================


#========================================================
# vir 다중 공산성 확인
#========================================================
# install.packages("car")
library(car)
vif(df_lm)
#========================================================
# vif 값이 10보다 작기 때문에 서로 각각의 변수들과 상관 정도가 높지 않아서 회귀 분석 모델 결과 분석 시 부정적 영향을 미치지 않음
#========================================================

#========================================================
# 다중 회귀분석
#========================================================
summary(df_lm)

#========================================================
# 변수 선택법 - 전진선택법, 후진소거법, 단계별 선택법
#========================================================
step(df_lm, scope = list(lower = ~1, upper = ~df$police + df$cctv + df$one_person + df$pub), direction = "forward")

step(df_lm, scope = list(lower = ~1, upper = ~df$police + df$cctv + df$one_person + df$pub), direction = "backward")

step(df_lm, scope = list(lower = ~1, upper = ~df$police + df$cctv + df$one_person + df$pub), direction = "both")

#========================================================
# crime에 영향을 미치는 요인은 pub, cctv, oneperson 변수로 확인
#========================================================


#========================================================
# K-means 군집화
#========================================================

#========================================================
# 다중 회귀분석에서 유의하지 않은 변수 제거
#========================================================
df <- subset(df,select = -c(police))

#========================================================
# 표준편차 0, 평균1로 표준화
#========================================================
df_scale = scale(df)
head(df_scale)

#========================================================
# NbClust() :  최적의 군집개수를 알려주는 다양한 지표 제공
#========================================================
# install.packages("NbClust")
library(NbClust)
set.seed(123)

#========================================================
# 유클리드 거리 / kmeans 군집 / 최소 군집 2개, 최대 군집 10개
#========================================================
nbC <- NbClust(df_scale, distance = "euclidean", method = "kmeans", min.nc = 2, max.nc = 10)

#========================================================
# 최적의 군집개수 확인
#========================================================
nbC$Best.nc
table(nbC$Best.nc[1,])

#========================================================
# 3개 군집으로 분류
#========================================================
clustering_km <- kmeans(df_scale, centers = 3, nstart = 15)
clustering_km$cluster   # 각 자치구가 어떤 군집에 들어갔는지 확인
clustering_km$centers   # 각 군집 center 특징
clustering_km$size      # 각 군집별 자치구 개수

#========================================================
# 군집데이터 시각화
#========================================================
library(cluster)
clusplot(x = df,
        clus = clustering_km$cluster,
        color = TRUE, shade = TRUE,
        labels = 2, lines = 0, main = "Cluster Plot")
#========================================================
# Kmeans 군집분석
#========================================================
num <- c(1:25) # 자치구 인덱스 
cluster_df <- clustering_km$cluster # 군집별 구 데이터
cluster_data <- data.frame(num, cluster_df)

#========================================================
# 군집별 구 데이터 분리
#========================================================
cluster_1 <- cluster_data[cluster_data$cluster_df == 1,]
cluster_2 <- cluster_data[cluster_data$cluster_df == 2,]
cluster_3 <- cluster_data[cluster_data$cluster_df == 3,]
cluster_3

#========================================================
# 기존 데이터베이스(df)에서 cluster별 데이터베이스 만들기
# num 기준으로 cluster에 변수 추가(one_person, cctv, pub, crime 등)
#========================================================

df <- data.frame(df, num)

cluster1_df <- df[cluster_1$num,]
cluster2_df <- df[cluster_2$num,]
cluster3_df <- df[cluster_3$num,]

#========================================================
# 첫 번째 군집분석에서 가장 위험지역이라고 판단된 2군집을 다시 Kmeans 군집분석을 통해 군집화
# Kmeans 
#========================================================
set.seed(123)
cluster2_df <- subset(cluster2_df, select = -c(num))
cluster2_df_scale = scale(cluster2_df)
library(NbClust)
set.seed(123)
nbC <- NbClust(cluster2_df_scale, distance = "euclidean", method = "kmeans", min.nc = 2, max.nc = 10)

#========================================================
# 가장 적절한 군집 찾기
#========================================================
nbC$Best.nc
table(nbC$Best.nc[1,])  # 4개

#========================================================
# 4개 군집으로 분류
#========================================================
clustering_km <- kmeans(cluster2_df_scale, centers = 4, nstart = 15)
clustering_km$cluster
clustering_km$centers
clustering_km$size

# 가장 시급한 지역 5, 11, 12 -> 동대문구, 동작구, 관악구
